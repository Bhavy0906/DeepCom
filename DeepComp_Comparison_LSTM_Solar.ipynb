{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "K7FaeNtgi2yT"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "1T8H6Pp_6evf"
      },
      "outputs": [],
      "source": [
        "data_train_csv1 = pd.read_csv('2011.csv', index_col=0)\n",
        "data_train_csv2 = pd.read_csv('2012.csv', index_col=0)\n",
        "data_train_csv  = pd.concat([data_train_csv1, data_train_csv2])\n",
        "data_val_csv    = pd.read_csv('2013.csv', index_col=0)\n",
        "data_test_csv   = pd.read_csv('2014.csv', index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "7uMkIVSIXceM"
      },
      "outputs": [],
      "source": [
        "# Data Preprocessing\n",
        "\n",
        "unit = 1 #unit: 60 minute\n",
        "\n",
        "RE_Capacity1 = max(data_train_csv['GHI'])\n",
        "RE_Capacity2 = max(data_val_csv['GHI'])\n",
        "RE_Capacity3 = max(data_test_csv['GHI'])\n",
        "\n",
        "size_train0 = int(len(data_train_csv)/unit)\n",
        "size_val0   = int(len(data_val_csv)/unit)\n",
        "size_test0  = int(len(data_test_csv)/unit)\n",
        "\n",
        "data_train0 = []\n",
        "data_train  = []\n",
        "for i in range(size_train0):\n",
        "    data_train0 += [round(pd.Series.mean(data_train_csv['GHI'][i*unit:(i+1)*unit])/RE_Capacity1, 3)]\n",
        "    data_train  += [data_train0[i]] if data_train0[i] > 0 else []\n",
        "\n",
        "data_val0 = []\n",
        "data_val  = []\n",
        "for i in range(size_val0):\n",
        "    data_val0 += [round(pd.Series.mean(data_val_csv['GHI'][i*unit:(i+1)*unit])/RE_Capacity2, 3)]\n",
        "    data_val  += [data_val0[i]] if data_val0[i] > 0 else []\n",
        "\n",
        "data_test0 = []\n",
        "data_test  = []\n",
        "for i in range(size_test0):\n",
        "    data_test0 += [round(pd.Series.mean(data_test_csv['GHI'][i*unit:(i+1)*unit])/RE_Capacity3, 3)]\n",
        "    data_test  += [data_test0[i]] if data_test0[i] > 0 else []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "vG4iSzn3i4nj"
      },
      "outputs": [],
      "source": [
        "# LSTM\n",
        "\n",
        "n_layers       = 1\n",
        "in_size        = 1\n",
        "hidden_size    = 16\n",
        "out_size       = 1\n",
        "batch_size     = 128\n",
        "learning_rate  = 0.001\n",
        "\n",
        "class LSTM(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LSTM, self).__init__()\n",
        "        self.fc_in  = nn.Linear(in_size, hidden_size)\n",
        "        self.rnn    = nn.LSTM(hidden_size, hidden_size, n_layers, batch_first=True)\n",
        "        self.fc_out = nn.Linear(hidden_size, out_size)\n",
        "    \n",
        "    def forward(self, x, hidden):\n",
        "        x = F.relu(self.fc_in(x))\n",
        "        x = x.view(1, -1, hidden_size)\n",
        "        x, hidden = self.rnn(x, hidden)\n",
        "        out = self.fc_out(x)\n",
        "        out = F.relu(out.view(-1, out_size))\n",
        "        return out, hidden\n",
        "        \n",
        "def train_net(model, batch, optimizer):\n",
        "    x, h, y = batch[0], batch[1], batch[2]\n",
        "    loss = F.mse_loss(model.forward(x, h)[0], y)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Nd2JyvdkNEi",
        "outputId": "faa8aefa-27ab-4792-d50b-e425a1fa57f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 1\n",
            "MAPE_train: 804.77%      MAPE_val: 793.98%        MAPE_test: 861.3%        \n",
            "------------------------------------------------------------------------------------------\n",
            "epoch: 10\n",
            "MAPE_train: 107.54%      MAPE_val: 112.89%        MAPE_test: 118.58%       \n",
            "------------------------------------------------------------------------------------------\n",
            "epoch: 20\n",
            "MAPE_train: 107.89%      MAPE_val: 114.2%         MAPE_test: 127.69%       \n",
            "------------------------------------------------------------------------------------------\n",
            "epoch: 30\n",
            "MAPE_train: 100.97%      MAPE_val: 107.96%        MAPE_test: 121.54%       \n",
            "------------------------------------------------------------------------------------------\n",
            "epoch: 40\n",
            "MAPE_train: 95.28%       MAPE_val: 101.01%        MAPE_test: 113.84%       \n",
            "------------------------------------------------------------------------------------------\n",
            "epoch: 50\n",
            "MAPE_train: 88.46%       MAPE_val: 91.63%         MAPE_test: 104.78%       \n",
            "------------------------------------------------------------------------------------------\n",
            "epoch: 60\n",
            "MAPE_train: 86.95%       MAPE_val: 89.3%          MAPE_test: 104.25%       \n",
            "------------------------------------------------------------------------------------------\n",
            "epoch: 70\n",
            "MAPE_train: 88.71%       MAPE_val: 90.79%         MAPE_test: 105.29%       \n",
            "------------------------------------------------------------------------------------------\n",
            "epoch: 80\n",
            "MAPE_train: 87.49%       MAPE_val: 88.14%         MAPE_test: 103.1%        \n",
            "------------------------------------------------------------------------------------------\n",
            "epoch: 90\n",
            "MAPE_train: 73.97%       MAPE_val: 74.84%         MAPE_test: 88.75%        \n",
            "------------------------------------------------------------------------------------------\n",
            "epoch: 100\n",
            "MAPE_train: 60.46%       MAPE_val: 59.96%         MAPE_test: 72.98%        \n",
            "------------------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Training LSTM\n",
        "\n",
        "total_epoch    = 100\n",
        "print_interval = 10\n",
        "\n",
        "model = LSTM()\n",
        "size_train = len(data_train)\n",
        "size_val = len(data_val)\n",
        "size_test = len(data_test)\n",
        "\n",
        "train_input = np.zeros((size_train-1, 1))\n",
        "train_output = np.zeros((size_train-1, 1))\n",
        "for i in range(size_train-1):\n",
        "    train_input[i,:] = data_train[i]\n",
        "    train_output[i,:] = data_train[i+1]\n",
        "\n",
        "val_input = np.zeros((size_val-1, 1))\n",
        "val_output = np.zeros((size_val-1, 1))\n",
        "for i in range(size_val-1):\n",
        "    val_input[i,:] = data_val[i]\n",
        "    val_output[i,:] = data_val[i+1]\n",
        "\n",
        "test_input = np.zeros((size_test-1, 1))\n",
        "test_output = np.zeros((size_test-1, 1))\n",
        "for i in range(size_test-1):\n",
        "    test_input[i,:] = data_test[i]\n",
        "    test_output[i,:] = data_test[i+1]\n",
        "\n",
        "total_batch = int((size_train-1)/batch_size) + 1\n",
        "pred_train, pred_val, pred_test = [], [], [] # Predicted Value\n",
        "mape_train, mape_val, mape_test = [], [], [] # Mean Absolute Percentage Error\n",
        "\n",
        "hidden = (torch.zeros([n_layers, 1, hidden_size], dtype=torch.float), torch.zeros([n_layers, 1, hidden_size], dtype=torch.float))\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "for epoch in range(total_epoch):\n",
        "    for i in range(total_batch):\n",
        "        batch_x = torch.tensor(train_input[batch_size*i:batch_size*(i+1),:] ,dtype=torch.float)\n",
        "        batch_y = torch.tensor(train_output[batch_size*i:batch_size*(i+1),:] ,dtype=torch.float)\n",
        "        batch = [batch_x, hidden, batch_y]\n",
        "        train_net(model, batch, optimizer)\n",
        "        _, hidden = model.forward(batch_x, hidden)\n",
        "        hidden = (hidden[0].detach(), hidden[1].detach())\n",
        "\n",
        "    hidden = (torch.zeros([n_layers, 1, hidden_size], dtype=torch.float), torch.zeros([n_layers, 1, hidden_size], dtype=torch.float))\n",
        "    if epoch == 0 or (epoch+1) % print_interval == 0:\n",
        "        train_predict = model.forward(torch.tensor(train_input, dtype=torch.float), hidden)[0].detach().numpy()\n",
        "        pred_train += [list(train_predict.flatten())]\n",
        "        mape_train += [list(np.abs(train_predict - train_output).flatten()/train_output.flatten())]\n",
        "        \n",
        "        val_predict = model.forward(torch.tensor(val_input, dtype=torch.float), hidden)[0].detach().numpy()\n",
        "        pred_val += [list(val_predict.flatten())]\n",
        "        mape_val += [list(np.abs(val_predict - val_output).flatten()/val_output.flatten())]\n",
        "        \n",
        "        test_predict = model.forward(torch.tensor(test_input, dtype=torch.float), hidden)[0].detach().numpy()\n",
        "        pred_test += [list(test_predict.flatten())]\n",
        "        mape_test += [list(np.abs(test_predict - test_output).flatten()/test_output.flatten())]\n",
        "\n",
        "        MAPE_train = round(100*np.mean(mape_train[-1]),2)\n",
        "        MAPE_val   = round(100*np.mean(mape_val[-1]),2)\n",
        "        MAPE_test  = round(100*np.mean(mape_test[-1]),2)\n",
        "\n",
        "        print(\"epoch: {}\".format(epoch+1))\n",
        "        print(\"MAPE_train: {}%\".format(MAPE_train).ljust(25), end=\"\")\n",
        "        print(\"MAPE_val: {}%\".format(MAPE_val).ljust(25), end=\"\")\n",
        "        print(\"MAPE_test: {}%\".format(MAPE_test).ljust(25))\n",
        "        print(\"------------------------------------------------------------------------------------------\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "cVxRZ0gHZbmn"
      },
      "outputs": [],
      "source": [
        "# Produce results\n",
        "\n",
        "select_num = np.argmin(np.mean(mape_val,axis=1))\n",
        "select_train = pd.DataFrame(np.array(pred_train[select_num][:]))\n",
        "select_val = pd.DataFrame(np.array(pred_val[select_num][:]))\n",
        "select_test = pd.DataFrame(np.array(pred_test[select_num][:]))\n",
        "select_val.to_csv(\"result/Solar_Model1_val\"+\".csv\")\n",
        "select_test.to_csv(\"result/Solar_Model1_NEC\"+\".csv\")\n",
        "select_train.to_csv(\"result/Solar_Model1_train\"+\".csv\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "authorship_tag": "ABX9TyMFmQvGjf+Cm/jtBxL1idnh",
      "collapsed_sections": [],
      "mount_file_id": "1cvkVbqmof-zArH3L2Z7t-GiyM7mS6iHx",
      "name": "DeepComp_Comparison_LSTM_Solar.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
