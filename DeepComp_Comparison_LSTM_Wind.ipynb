{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mDQqKc8C-Ofy"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1Jz07bAo6t5G"
      },
      "outputs": [],
      "source": [
        "data_train_csv1 = pd.read_csv('2011.csv', index_col=0)\n",
        "data_train_csv2 = pd.read_csv('2012.csv', index_col=0)\n",
        "data_train_csv  = pd.concat([data_train_csv1, data_train_csv2])\n",
        "data_val_csv    = pd.read_csv('2013.csv', index_col=0)\n",
        "data_test_csv   = pd.read_csv('2014.csv', index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WUtd8sOT-UoQ"
      },
      "outputs": [],
      "source": [
        "# Data Preprocessing\n",
        "\n",
        "unit = 1 #unit: 60 minute\n",
        "\n",
        "RE_Capacity1 = max(data_train_csv['Wind Speed'])\n",
        "RE_Capacity2 = max(data_val_csv['Wind Speed'])\n",
        "RE_Capacity3 = max(data_test_csv['Wind Speed'])\n",
        "\n",
        "size_train0 = int(len(data_train_csv)/unit)\n",
        "size_val0   = int(len(data_val_csv)/unit)\n",
        "size_test0  = int(len(data_test_csv)/unit)\n",
        "\n",
        "data_train0 = []\n",
        "data_train  = []\n",
        "for i in range(size_train0):\n",
        "    data_train0 += [round(pd.Series.mean(data_train_csv['Wind Speed'][i*unit:(i+1)*unit])/RE_Capacity1, 3)]\n",
        "    data_train  += [data_train0[i]] if data_train0[i] > 0 else []\n",
        "\n",
        "data_val0 = []\n",
        "data_val  = []\n",
        "for i in range(size_val0):\n",
        "    data_val0 += [round(pd.Series.mean(data_val_csv['Wind Speed'][i*unit:(i+1)*unit])/RE_Capacity2, 3)]\n",
        "    data_val  += [data_val0[i]] if data_val0[i] > 0 else []\n",
        "\n",
        "data_test0 = []\n",
        "data_test  = []\n",
        "for i in range(size_test0):\n",
        "    data_test0 += [round(pd.Series.mean(data_test_csv['Wind Speed'][i*unit:(i+1)*unit])/RE_Capacity3, 3)]\n",
        "    data_test  += [data_test0[i]] if data_test0[i] > 0 else []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ws0q-rxs-V44"
      },
      "outputs": [],
      "source": [
        "# LSTM\n",
        "\n",
        "n_layers       = 1\n",
        "in_size        = 1\n",
        "hidden_size    = 16\n",
        "out_size       = 1\n",
        "batch_size     = 128\n",
        "learning_rate  = 0.001\n",
        "\n",
        "class LSTM(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LSTM, self).__init__()\n",
        "        self.fc_in  = nn.Linear(in_size, hidden_size)\n",
        "        self.rnn    = nn.LSTM(hidden_size, hidden_size, n_layers, batch_first=True)\n",
        "        self.fc_out = nn.Linear(hidden_size, out_size)\n",
        "    \n",
        "    def forward(self, x, hidden):\n",
        "        x = F.relu(self.fc_in(x))\n",
        "        x = x.view(1, -1, hidden_size)\n",
        "        x, hidden = self.rnn(x, hidden)\n",
        "        out = self.fc_out(x)\n",
        "        out = F.relu(out.view(-1, out_size))\n",
        "        return out, hidden\n",
        "        \n",
        "def train_net(model, batch, optimizer):\n",
        "    x, h, y = batch[0], batch[1], batch[2]\n",
        "    loss = F.mse_loss(model.forward(x, h)[0], y)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5rVzBsK-Wyr",
        "outputId": "db5dacf4-ce3d-40d7-a975-49c7092c5bc6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 1\n",
            "MAPE_train: 32.16%       MAPE_val: 32.61%         MAPE_test: 35.93%        \n",
            "------------------------------------------------------------------------------------------\n",
            "epoch: 10\n",
            "MAPE_train: 8.08%        MAPE_val: 7.87%          MAPE_test: 8.7%          \n",
            "------------------------------------------------------------------------------------------\n",
            "epoch: 20\n",
            "MAPE_train: 7.63%        MAPE_val: 7.37%          MAPE_test: 8.13%         \n",
            "------------------------------------------------------------------------------------------\n",
            "epoch: 30\n",
            "MAPE_train: 7.68%        MAPE_val: 7.48%          MAPE_test: 8.23%         \n",
            "------------------------------------------------------------------------------------------\n",
            "epoch: 40\n",
            "MAPE_train: 7.68%        MAPE_val: 7.48%          MAPE_test: 8.22%         \n",
            "------------------------------------------------------------------------------------------\n",
            "epoch: 50\n",
            "MAPE_train: 7.65%        MAPE_val: 7.45%          MAPE_test: 8.17%         \n",
            "------------------------------------------------------------------------------------------\n",
            "epoch: 60\n",
            "MAPE_train: 7.63%        MAPE_val: 7.42%          MAPE_test: 8.14%         \n",
            "------------------------------------------------------------------------------------------\n",
            "epoch: 70\n",
            "MAPE_train: 7.65%        MAPE_val: 7.44%          MAPE_test: 8.23%         \n",
            "------------------------------------------------------------------------------------------\n",
            "epoch: 80\n",
            "MAPE_train: 7.59%        MAPE_val: 7.36%          MAPE_test: 8.18%         \n",
            "------------------------------------------------------------------------------------------\n",
            "epoch: 90\n",
            "MAPE_train: 7.55%        MAPE_val: 7.32%          MAPE_test: 8.16%         \n",
            "------------------------------------------------------------------------------------------\n",
            "epoch: 100\n",
            "MAPE_train: 7.55%        MAPE_val: 7.33%          MAPE_test: 8.18%         \n",
            "------------------------------------------------------------------------------------------\n",
            "epoch: 110\n",
            "MAPE_train: 7.57%        MAPE_val: 7.34%          MAPE_test: 8.23%         \n",
            "------------------------------------------------------------------------------------------\n",
            "epoch: 120\n",
            "MAPE_train: 7.59%        MAPE_val: 7.37%          MAPE_test: 8.29%         \n",
            "------------------------------------------------------------------------------------------\n",
            "epoch: 130\n",
            "MAPE_train: 7.59%        MAPE_val: 7.37%          MAPE_test: 8.31%         \n",
            "------------------------------------------------------------------------------------------\n",
            "epoch: 140\n",
            "MAPE_train: 7.58%        MAPE_val: 7.37%          MAPE_test: 8.32%         \n",
            "------------------------------------------------------------------------------------------\n",
            "epoch: 150\n",
            "MAPE_train: 7.57%        MAPE_val: 7.36%          MAPE_test: 8.31%         \n",
            "------------------------------------------------------------------------------------------\n",
            "epoch: 160\n",
            "MAPE_train: 7.56%        MAPE_val: 7.35%          MAPE_test: 8.31%         \n",
            "------------------------------------------------------------------------------------------\n",
            "epoch: 170\n",
            "MAPE_train: 7.55%        MAPE_val: 7.34%          MAPE_test: 8.31%         \n",
            "------------------------------------------------------------------------------------------\n",
            "epoch: 180\n",
            "MAPE_train: 7.54%        MAPE_val: 7.33%          MAPE_test: 8.31%         \n",
            "------------------------------------------------------------------------------------------\n",
            "epoch: 190\n",
            "MAPE_train: 7.53%        MAPE_val: 7.33%          MAPE_test: 8.31%         \n",
            "------------------------------------------------------------------------------------------\n",
            "epoch: 200\n",
            "MAPE_train: 7.54%        MAPE_val: 7.33%          MAPE_test: 8.32%         \n",
            "------------------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Training LSTM\n",
        "\n",
        "total_epoch    = 200\n",
        "print_interval = 10\n",
        "\n",
        "model = LSTM()\n",
        "size_train = len(data_train)\n",
        "size_val = len(data_val)\n",
        "size_test = len(data_test)\n",
        "\n",
        "train_input = np.zeros((size_train-1, 1))\n",
        "train_output = np.zeros((size_train-1, 1))\n",
        "for i in range(size_train-1):\n",
        "    train_input[i,:] = data_train[i]\n",
        "    train_output[i,:] = data_train[i+1]\n",
        "\n",
        "val_input = np.zeros((size_val-1, 1))\n",
        "val_output = np.zeros((size_val-1, 1))\n",
        "for i in range(size_val-1):\n",
        "    val_input[i,:] = data_val[i]\n",
        "    val_output[i,:] = data_val[i+1]\n",
        "\n",
        "test_input = np.zeros((size_test-1, 1))\n",
        "test_output = np.zeros((size_test-1, 1))\n",
        "for i in range(size_test-1):\n",
        "    test_input[i,:] = data_test[i]\n",
        "    test_output[i,:] = data_test[i+1]\n",
        "\n",
        "total_batch = int((size_train-1)/batch_size) + 1\n",
        "pred_train, pred_val, pred_test = [], [], [] # Predicted Value\n",
        "mape_train, mape_val, mape_test = [], [], [] # Mean Absolute Percentage Error\n",
        "\n",
        "hidden = (torch.zeros([n_layers, 1, hidden_size], dtype=torch.float), torch.zeros([n_layers, 1, hidden_size], dtype=torch.float))\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "for epoch in range(total_epoch):\n",
        "    for i in range(total_batch):\n",
        "        batch_x = torch.tensor(train_input[batch_size*i:batch_size*(i+1),:] ,dtype=torch.float)\n",
        "        batch_y = torch.tensor(train_output[batch_size*i:batch_size*(i+1),:] ,dtype=torch.float)\n",
        "        batch = [batch_x, hidden, batch_y]\n",
        "        train_net(model, batch, optimizer)\n",
        "        _, hidden = model.forward(batch_x, hidden)\n",
        "        hidden = (hidden[0].detach(), hidden[1].detach())\n",
        "\n",
        "    hidden = (torch.zeros([n_layers, 1, hidden_size], dtype=torch.float), torch.zeros([n_layers, 1, hidden_size], dtype=torch.float))\n",
        "    if epoch == 0 or (epoch+1) % print_interval == 0:\n",
        "        train_predict = model.forward(torch.tensor(train_input, dtype=torch.float), hidden)[0].detach().numpy()\n",
        "        pred_train += [list(train_predict.flatten())]\n",
        "        mape_train += [list(np.abs(train_predict - train_output).flatten()/train_output.flatten())]\n",
        "        \n",
        "        val_predict = model.forward(torch.tensor(val_input, dtype=torch.float), hidden)[0].detach().numpy()\n",
        "        pred_val += [list(val_predict.flatten())]\n",
        "        mape_val += [list(np.abs(val_predict - val_output).flatten()/val_output.flatten())]\n",
        "        \n",
        "        test_predict = model.forward(torch.tensor(test_input, dtype=torch.float), hidden)[0].detach().numpy()\n",
        "        pred_test += [list(test_predict.flatten())]\n",
        "        mape_test += [list(np.abs(test_predict - test_output).flatten()/test_output.flatten())]\n",
        "\n",
        "        MAPE_train = round(100*np.mean(mape_train[-1]),2)\n",
        "        MAPE_val   = round(100*np.mean(mape_val[-1]),2)\n",
        "        MAPE_test  = round(100*np.mean(mape_test[-1]),2)\n",
        "\n",
        "        print(\"epoch: {}\".format(epoch+1))\n",
        "        print(\"MAPE_train: {}%\".format(MAPE_train).ljust(25), end=\"\")\n",
        "        print(\"MAPE_val: {}%\".format(MAPE_val).ljust(25), end=\"\")\n",
        "        print(\"MAPE_test: {}%\".format(MAPE_test).ljust(25))\n",
        "        print(\"------------------------------------------------------------------------------------------\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Y_wer76M-YMb"
      },
      "outputs": [],
      "source": [
        "# Produce results\n",
        "#\n",
        "select_num = np.argmin(np.mean(mape_val,axis=1))\n",
        "select_train = pd.DataFrame(np.array(pred_train[select_num][:]))\n",
        "select_val = pd.DataFrame(np.array(pred_val[select_num][:]))\n",
        "select_test = pd.DataFrame(np.array(pred_test[select_num][:]))\n",
        "select_val.to_csv(\"result/Wind_Model1_val\"+\".csv\")\n",
        "select_test.to_csv(\"result/Wind_Model1_NEC\"+\".csv\")\n",
        "select_train.to_csv(\"result/Wind_Model1_train\"+\".csv\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOWe/Ldu5InhQJSOw1dGpM0",
      "collapsed_sections": [],
      "mount_file_id": "12SpbdQs6BV-XVLpMWbtHcbruJ-s40DxV",
      "name": "DeepComp_Comparison_LSTM_Wind.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
