{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "sbHJdT8wYOpD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import collections\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "g4ulsTOX8Fr3"
      },
      "outputs": [],
      "source": [
        "Renewable_Energy = \"Wind\"\n",
        "\n",
        "data_train_csv1 = pd.read_csv('2011.csv', index_col=0)\n",
        "data_train_csv2 = pd.read_csv('2012.csv', index_col=0)\n",
        "data_train_csv  = pd.concat([data_train_csv1, data_train_csv2])\n",
        "data_val_csv    = pd.read_csv('2013.csv', index_col=0)\n",
        "data_test_csv   = pd.read_csv('2014.csv', index_col=0)\n",
        "\n",
        "train_predict = np.array(pd.read_csv(\"result/\"+Renewable_Energy+\"_Model1_train.csv\", index_col=0))\n",
        "val_predict = np.array(pd.read_csv(\"result/\"+Renewable_Energy+\"_Model1_val.csv\", index_col=0))\n",
        "test_predict = np.array(pd.read_csv(\"result/\"+Renewable_Energy+\"_Model1_NEC.csv\", index_col=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "dxexWoP71odN"
      },
      "outputs": [],
      "source": [
        "# Data Preprocessing\n",
        "\n",
        "Battery_Size = 0.5\n",
        "unit         = 1 #unit: 60 minute\n",
        "\n",
        "RE_Capacity1 = max(data_train_csv['Wind Speed'])\n",
        "RE_Capacity2 = max(data_val_csv['Wind Speed'])\n",
        "RE_Capacity3 = max(data_test_csv['Wind Speed'])\n",
        "\n",
        "size_train0 = int(len(data_train_csv)/unit)\n",
        "size_val0   = int(len(data_val_csv)/unit)\n",
        "size_test0  = int(len(data_test_csv)/unit)\n",
        "\n",
        "data_train0 = []\n",
        "data_train  = []\n",
        "for i in range(size_train0):\n",
        "    data_train0 += [round(pd.Series.mean(data_train_csv['Wind Speed'][i*unit:(i+1)*unit])/RE_Capacity1, 3)]\n",
        "    data_train  += [data_train0[i]] if data_train0[i] > 0 else []\n",
        "\n",
        "data_val0 = []\n",
        "data_val  = []\n",
        "for i in range(size_val0):\n",
        "    data_val0 += [round(pd.Series.mean(data_val_csv['Wind Speed'][i*unit:(i+1)*unit])/RE_Capacity2, 3)]\n",
        "    data_val  += [data_val0[i]] if data_val0[i] > 0 else []\n",
        "\n",
        "data_test0 = []\n",
        "data_test  = []\n",
        "for i in range(size_test0):\n",
        "    data_test0 += [round(pd.Series.mean(data_test_csv['Wind Speed'][i*unit:(i+1)*unit])/RE_Capacity3, 3)]\n",
        "    data_test  += [data_test0[i]] if data_test0[i] > 0 else []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGQrvrAZZ4SG",
        "outputId": "3c2847df-61b0-4a04-b6d5-f213f6e560cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MAPE_train: 7.55%        MAPE_val: 7.32%          MAPE_test: 8.16%         \n"
          ]
        }
      ],
      "source": [
        "size_train = len(data_train)\n",
        "size_val = len(data_val)\n",
        "size_test = len(data_test)\n",
        "\n",
        "train_input = np.zeros((size_train-1, 1))\n",
        "train_output = np.zeros((size_train-1, 1))\n",
        "for i in range(size_train-1):\n",
        "    train_input[i,:] = data_train[i]\n",
        "    train_output[i,:] = data_train[i+1]\n",
        "\n",
        "val_input = np.zeros((size_val-1, 1))\n",
        "val_output = np.zeros((size_val-1, 1))\n",
        "for i in range(size_val-1):\n",
        "    val_input[i,:] = data_val[i]\n",
        "    val_output[i,:] = data_val[i+1]\n",
        "\n",
        "test_input = np.zeros((size_test-1, 1))\n",
        "test_output = np.zeros((size_test-1, 1))\n",
        "for i in range(size_test-1):\n",
        "    test_input[i,:] = data_test[i]\n",
        "    test_output[i,:] = data_test[i+1]\n",
        "\n",
        "print(\"MAPE_train: {}%\".format(round(100*np.mean(np.abs(train_predict - train_output)/train_output),2)).ljust(25), end=\"\")\n",
        "print(\"MAPE_val: {}%\".format(round(100*np.mean(np.abs(val_predict - val_output)/val_output),2)).ljust(25), end=\"\")\n",
        "print(\"MAPE_test: {}%\".format(round(100*np.mean(np.abs(test_predict - test_output)/test_output),2)).ljust(25))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "1orT-K3n34nr"
      },
      "outputs": [],
      "source": [
        "# SARSA\n",
        "\n",
        "in_size       = 1\n",
        "out_size      = 5\n",
        "gamma         = 0.99\n",
        "epsilon       = 0.9\n",
        "batch_size    = 128\n",
        "learning_rate = 0.001\n",
        "\n",
        "class SARSA(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SARSA, self).__init__()\n",
        "        self.fc = nn.Linear(in_size, out_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "        \n",
        "def train_net(model, batch, optimizer):\n",
        "    s_lst, a_lst, r_lst, s_prime_lst = [], [], [], []\n",
        "\n",
        "    for transition in batch:\n",
        "        s, a, r, s_prime = transition\n",
        "        s_lst.append(s)\n",
        "        a_lst.append([a])\n",
        "        r_lst.append([r])\n",
        "        s_prime_lst.append(s_prime)\n",
        "\n",
        "    s,a,r,s_prime = torch.tensor(s_lst, dtype=torch.float), torch.tensor(a_lst), \\\n",
        "                    torch.tensor(r_lst, dtype=torch.float), torch.tensor(s_prime_lst, dtype=torch.float)\n",
        "            \n",
        "    for i in range(10):\n",
        "        q_out = model.forward(s).gather(1,a)\n",
        "        target = r + gamma * torch.mean(model.forward(s_prime))\n",
        "        loss = F.mse_loss(q_out, target)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FM9xx8yDEf5x",
        "outputId": "3357d47c-6f08-429e-fb3e-c0ff311034dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "episode: 1\n",
            "MAPE_train: 7.63%        MAPE_val: 3.16%          MAPE_test: 3.55%         \n",
            "CCR_train: 0.531         CCR_val: 0.707           CCR_test: 0.707          \n",
            "------------------------------------------------------------------------------------------\n",
            "episode: 2\n",
            "MAPE_train: 7.24%        MAPE_val: 2.29%          MAPE_test: 2.53%         \n",
            "CCR_train: 0.529         CCR_val: 0.856           CCR_test: 0.869          \n",
            "------------------------------------------------------------------------------------------\n",
            "episode: 3\n",
            "MAPE_train: 7.32%        MAPE_val: 2.24%          MAPE_test: 2.49%         \n",
            "CCR_train: 0.537         CCR_val: 0.865           CCR_test: 0.874          \n",
            "------------------------------------------------------------------------------------------\n",
            "episode: 4\n",
            "MAPE_train: 7.2%         MAPE_val: 3.7%           MAPE_test: 3.88%         \n",
            "CCR_train: 0.538         CCR_val: 0.655           CCR_test: 0.705          \n",
            "------------------------------------------------------------------------------------------\n",
            "episode: 5\n",
            "MAPE_train: 7.37%        MAPE_val: 2.4%           MAPE_test: 2.61%         \n",
            "CCR_train: 0.539         CCR_val: 0.837           CCR_test: 0.858          \n",
            "------------------------------------------------------------------------------------------\n",
            "episode: 6\n",
            "MAPE_train: 7.16%        MAPE_val: 3.16%          MAPE_test: 3.56%         \n",
            "CCR_train: 0.539         CCR_val: 0.708           CCR_test: 0.708          \n",
            "------------------------------------------------------------------------------------------\n",
            "episode: 7\n",
            "MAPE_train: 7.19%        MAPE_val: 3.18%          MAPE_test: 3.57%         \n",
            "CCR_train: 0.533         CCR_val: 0.705           CCR_test: 0.703          \n",
            "------------------------------------------------------------------------------------------\n",
            "episode: 8\n",
            "MAPE_train: 7.19%        MAPE_val: 3.17%          MAPE_test: 3.57%         \n",
            "CCR_train: 0.532         CCR_val: 0.705           CCR_test: 0.704          \n",
            "------------------------------------------------------------------------------------------\n",
            "episode: 9\n",
            "MAPE_train: 7.21%        MAPE_val: 2.82%          MAPE_test: 3.22%         \n",
            "CCR_train: 0.535         CCR_val: 0.777           CCR_test: 0.77           \n",
            "------------------------------------------------------------------------------------------\n",
            "episode: 10\n",
            "MAPE_train: 7.39%        MAPE_val: 3.16%          MAPE_test: 3.56%         \n",
            "CCR_train: 0.538         CCR_val: 0.707           CCR_test: 0.707          \n",
            "------------------------------------------------------------------------------------------\n",
            "episode: 11\n",
            "MAPE_train: 7.55%        MAPE_val: 2.29%          MAPE_test: 2.52%         \n",
            "CCR_train: 0.534         CCR_val: 0.857           CCR_test: 0.87           \n",
            "------------------------------------------------------------------------------------------\n",
            "episode: 12\n",
            "MAPE_train: 7.42%        MAPE_val: 3.16%          MAPE_test: 3.56%         \n",
            "CCR_train: 0.534         CCR_val: 0.706           CCR_test: 0.706          \n",
            "------------------------------------------------------------------------------------------\n",
            "episode: 13\n",
            "MAPE_train: 8.07%        MAPE_val: 3.17%          MAPE_test: 3.57%         \n",
            "CCR_train: 0.54          CCR_val: 0.705           CCR_test: 0.703          \n",
            "------------------------------------------------------------------------------------------\n",
            "episode: 14\n",
            "MAPE_train: 7.72%        MAPE_val: 3.16%          MAPE_test: 3.56%         \n",
            "CCR_train: 0.543         CCR_val: 0.707           CCR_test: 0.707          \n",
            "------------------------------------------------------------------------------------------\n",
            "episode: 15\n",
            "MAPE_train: 7.14%        MAPE_val: 3.17%          MAPE_test: 3.57%         \n",
            "CCR_train: 0.53          CCR_val: 0.704           CCR_test: 0.704          \n",
            "------------------------------------------------------------------------------------------\n",
            "episode: 16\n",
            "MAPE_train: 7.42%        MAPE_val: 3.16%          MAPE_test: 3.56%         \n",
            "CCR_train: 0.53          CCR_val: 0.707           CCR_test: 0.707          \n",
            "------------------------------------------------------------------------------------------\n",
            "episode: 17\n",
            "MAPE_train: 7.39%        MAPE_val: 2.39%          MAPE_test: 2.63%         \n",
            "CCR_train: 0.529         CCR_val: 0.842           CCR_test: 0.854          \n",
            "------------------------------------------------------------------------------------------\n",
            "episode: 18\n",
            "MAPE_train: 7.22%        MAPE_val: 2.66%          MAPE_test: 3.04%         \n",
            "CCR_train: 0.539         CCR_val: 0.802           CCR_test: 0.797          \n",
            "------------------------------------------------------------------------------------------\n",
            "episode: 19\n",
            "MAPE_train: 7.52%        MAPE_val: 3.16%          MAPE_test: 3.56%         \n",
            "CCR_train: 0.538         CCR_val: 0.706           CCR_test: 0.707          \n",
            "------------------------------------------------------------------------------------------\n",
            "episode: 20\n",
            "MAPE_train: 7.34%        MAPE_val: 2.58%          MAPE_test: 2.92%         \n",
            "CCR_train: 0.535         CCR_val: 0.815           CCR_test: 0.82           \n",
            "------------------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Training SARSA\n",
        "\n",
        "E_max   = Battery_Size\n",
        "tdelta  = unit\n",
        "eff_c   = 0.9\n",
        "eff_d   = 0.9\n",
        "soc_min = 0.1\n",
        "soc_max = 0.9\n",
        "P_cmax  = Battery_Size/3\n",
        "P_dmax  = Battery_Size/3\n",
        "beta_c  = 0.01\n",
        "beta_d  = 0.01\n",
        "\n",
        "E_cmax = eff_c*P_cmax*tdelta\n",
        "E_dmax = (1/eff_d)*P_dmax*tdelta\n",
        "C_max  = int(out_size/2)\n",
        "\n",
        "total_episode = 20\n",
        "print_interval = 1\n",
        "\n",
        "model = SARSA()\n",
        "act_train,  act_val,  act_test  = [], [], [] # Controlled Value\n",
        "mape_train, mape_val, mape_test = [], [], [] # Mean Absolute Percentage Error\n",
        "ccr_train,  ccr_val,  ccr_test  = [], [], [] # Complete Compensation Ratio\n",
        "\n",
        "batch = collections.deque(maxlen=batch_size+1)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "for n_epi in range(total_episode):\n",
        "    act_train  += [[]]; act_val  += [[]]; act_test  += [[]]\n",
        "    mape_train += [[]]; mape_val += [[]]; mape_test += [[]]\n",
        "    ccr_train  += [[]]; ccr_val  += [[]]; ccr_test  += [[]]\n",
        "\n",
        "    state = [E_max/2]\n",
        "    i = 0\n",
        "    while i < size_train-1:\n",
        "        for t in range(batch_size):\n",
        "            coin = torch.rand(1).item()\n",
        "            if coin < epsilon:\n",
        "                action = np.random.choice(range(out_size))\n",
        "            else:\n",
        "                Qout = model.forward(torch.tensor(state, dtype=torch.float))\n",
        "                action = np.argmax(Qout.tolist())\n",
        "            E_c = min(max((E_cmax/C_max)*(action-C_max), 0.0), E_max*soc_max - state[0])\n",
        "            E_d = min(max((E_dmax/C_max)*(C_max-action), 0.0), state[0] - E_max*soc_min)\n",
        "\n",
        "            real = train_output[i][0] + eff_d*E_d/tdelta - (1/eff_c)*E_c/tdelta\n",
        "            pred = train_predict[i][0]\n",
        "\n",
        "            E = state[0] + E_c - E_d\n",
        "            P_climit = min(P_cmax, (1/eff_c)*(E_max*soc_max - E)/tdelta)\n",
        "            P_dlimit = min(P_dmax, eff_d*(E - E_max*soc_min)/tdelta)\n",
        "            P_c = min(max(real-pred, 0), P_climit)\n",
        "            P_d = min(max(pred-real, 0), P_dlimit)\n",
        "            E_prime = E + eff_c*P_c*tdelta - (1/eff_d)*P_d*tdelta\n",
        "            disp = 0.0 if np.isclose(real - P_c + P_d, 0) else real - P_c + P_d\n",
        "            error = pred - disp\n",
        "            error_function = abs(error) + beta_c*P_c + beta_d*P_d\n",
        "\n",
        "            next_state = [E_prime]\n",
        "            reward = -error_function\n",
        "            batch.append((state, action, reward, next_state))\n",
        "            state = next_state[:]\n",
        "\n",
        "            act_train[n_epi]  += [E_c - E_d]\n",
        "            mape_train[n_epi]  += [abs((pred-disp)/disp)] if disp != 0 else [0]\n",
        "            ccr_train[n_epi] += [1 if np.isclose(pred-disp,0) else 0]\n",
        "            i += 1\n",
        "            if i == size_train-1:\n",
        "                break\n",
        "\n",
        "        if n_epi != 0:\n",
        "            train_net(model, batch, optimizer)\n",
        "    \n",
        "    state = [E_max/2]\n",
        "    for k in range(size_val-1):\n",
        "        Qout = model.forward(torch.tensor(state, dtype=torch.float))\n",
        "        action = np.argmax(Qout.tolist())\n",
        "        E_c = min(max((E_cmax/C_max)*(action-C_max), 0.0), E_max*soc_max - state[0])\n",
        "        E_d = min(max((E_dmax/C_max)*(C_max-action), 0.0), state[0] - E_max*soc_min)\n",
        "\n",
        "        real = val_output[k][0] + eff_d*E_d/tdelta - (1/eff_c)*E_c/tdelta\n",
        "        pred = val_predict[k][0]\n",
        "\n",
        "        E = state[0] + E_c - E_d\n",
        "        P_climit = min(P_cmax, (1/eff_c)*(E_max*soc_max - E)/tdelta)\n",
        "        P_dlimit = min(P_dmax, eff_d*(E - E_max*soc_min)/tdelta)\n",
        "        P_c = min(max(real-pred, 0), P_climit)\n",
        "        P_d = min(max(pred-real, 0), P_dlimit)\n",
        "        E_prime = E + eff_c*P_c*tdelta - (1/eff_d)*P_d*tdelta\n",
        "        disp = 0.0 if np.isclose(real - P_c + P_d, 0) else real - P_c + P_d\n",
        "        error = pred - disp\n",
        "        error_function = abs(error) + beta_c*P_c + beta_d*P_d\n",
        "\n",
        "        next_state = [E_prime]\n",
        "        state = next_state[:]\n",
        "\n",
        "        act_val[n_epi]  += [E_c - E_d]\n",
        "        mape_val[n_epi]  += [abs((pred-disp)/disp)] if disp != 0 else [0]\n",
        "        ccr_val[n_epi] += [1 if np.isclose(pred-disp,0) else 0]\n",
        "    \n",
        "    state = [E_max/2]\n",
        "    for l in range(size_test-1):\n",
        "        Qout = model.forward(torch.tensor(state, dtype=torch.float))\n",
        "        action = np.argmax(Qout.tolist())\n",
        "        E_c = min(max((E_cmax/C_max)*(action-C_max), 0.0), E_max*soc_max - state[0])\n",
        "        E_d = min(max((E_dmax/C_max)*(C_max-action), 0.0), state[0] - E_max*soc_min)\n",
        "\n",
        "        real = test_output[l][0] + eff_d*E_d/tdelta - (1/eff_c)*E_c/tdelta\n",
        "        pred = test_predict[l][0]\n",
        "\n",
        "        E = state[0] + E_c - E_d\n",
        "        P_climit = min(P_cmax, (1/eff_c)*(E_max*soc_max - E)/tdelta)\n",
        "        P_dlimit = min(P_dmax, eff_d*(E - E_max*soc_min)/tdelta)\n",
        "        P_c = min(max(real-pred, 0), P_climit)\n",
        "        P_d = min(max(pred-real, 0), P_dlimit)\n",
        "        E_prime = E + eff_c*P_c*tdelta - (1/eff_d)*P_d*tdelta\n",
        "        disp = 0.0 if np.isclose(real - P_c + P_d, 0) else real - P_c + P_d\n",
        "        error = pred - disp\n",
        "        error_function = abs(error) + beta_c*P_c + beta_d*P_d\n",
        "\n",
        "        next_state = [E_prime]\n",
        "        state = next_state[:]\n",
        "\n",
        "        act_test[n_epi]  += [E_c - E_d]\n",
        "        mape_test[n_epi]  += [abs((pred-disp)/disp)] if disp != 0 else [0]\n",
        "        ccr_test[n_epi] += [1 if np.isclose(pred-disp,0) else 0]\n",
        "    \n",
        "    if (n_epi+1)%print_interval == 0:\n",
        "        MAPE_train = round(100*np.mean(mape_train[n_epi]),2)\n",
        "        MAPE_val   = round(100*np.mean(mape_val[n_epi]),2)\n",
        "        MAPE_test  = round(100*np.mean(mape_test[n_epi]),2)\n",
        "        CCR_train  = round(np.mean(ccr_train[n_epi]),3)\n",
        "        CCR_val    = round(np.mean(ccr_val[n_epi]),3)\n",
        "        CCR_test   = round(np.mean(ccr_test[n_epi]),3)\n",
        "\n",
        "        print(\"episode: {}\".format(n_epi+1))\n",
        "        print(\"MAPE_train: {}%\".format(MAPE_train).ljust(25), end=\"\")\n",
        "        print(\"MAPE_val: {}%\".format(MAPE_val).ljust(25), end=\"\")\n",
        "        print(\"MAPE_test: {}%\".format(MAPE_test).ljust(25))\n",
        "        print(\"CCR_train: {}\".format(CCR_train).ljust(25), end=\"\")\n",
        "        print(\"CCR_val: {}\".format(CCR_val).ljust(25), end=\"\")\n",
        "        print(\"CCR_test: {}\".format(CCR_test).ljust(25))\n",
        "        print(\"------------------------------------------------------------------------------------------\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "LxA-zDA6Y02K"
      },
      "outputs": [],
      "source": [
        "# Produce results\n",
        "\n",
        "select_num = np.argmin(np.mean(mape_val,axis=1))\n",
        "select = pd.DataFrame(np.array(act_test[select_num][:]))\n",
        "select.to_csv(\"result/Wind_Model2_ECC+_\"+str(int(100*E_max))+\".csv\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMnPKlZQ6DG1XY9mDRuOotm",
      "collapsed_sections": [],
      "mount_file_id": "17dao2LY64aYIEp53suvEygPWgsO8auJq",
      "name": "DeepComp_Comparison_SARSA_Wind.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
