{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "TfXXnaufrfAQ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import collections\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Fhhm33nh8Agv"
      },
      "outputs": [],
      "source": [
        "Renewable_Energy = \"Solar\"\n",
        "\n",
        "data_train_csv1 = pd.read_csv('2011.csv', index_col=0)\n",
        "data_train_csv2 = pd.read_csv('2012.csv', index_col=0)\n",
        "data_train_csv  = pd.concat([data_train_csv1, data_train_csv2])\n",
        "data_val_csv    = pd.read_csv('2013.csv', index_col=0)\n",
        "data_test_csv   = pd.read_csv('2014.csv', index_col=0)\n",
        "\n",
        "train_predict = np.array(pd.read_csv(\"result/\"+Renewable_Energy+\"_Model1_train.csv\", index_col=0))\n",
        "val_predict = np.array(pd.read_csv(\"result/\"+Renewable_Energy+\"_Model1_val.csv\", index_col=0))\n",
        "test_predict = np.array(pd.read_csv(\"result/\"+Renewable_Energy+\"_Model1_NEC.csv\", index_col=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "HEaT0jerrgg-"
      },
      "outputs": [],
      "source": [
        "# Data Preprocessing\n",
        "\n",
        "Battery_Size = 0.4\n",
        "unit         = 1 #unit: 60 minute\n",
        "\n",
        "RE_Capacity1 = max(data_train_csv['GHI'])\n",
        "RE_Capacity2 = max(data_val_csv['GHI'])\n",
        "RE_Capacity3 = max(data_test_csv['GHI'])\n",
        "\n",
        "size_train0 = int(len(data_train_csv)/unit)\n",
        "size_val0   = int(len(data_val_csv)/unit)\n",
        "size_test0  = int(len(data_test_csv)/unit)\n",
        "\n",
        "data_train0 = []\n",
        "data_train  = []\n",
        "for i in range(size_train0):\n",
        "    data_train0 += [round(pd.Series.mean(data_train_csv['GHI'][i*unit:(i+1)*unit])/RE_Capacity1, 3)]\n",
        "    data_train  += [data_train0[i]] if data_train0[i] > 0 else []\n",
        "\n",
        "data_val0 = []\n",
        "data_val  = []\n",
        "for i in range(size_val0):\n",
        "    data_val0 += [round(pd.Series.mean(data_val_csv['GHI'][i*unit:(i+1)*unit])/RE_Capacity2, 3)]\n",
        "    data_val  += [data_val0[i]] if data_val0[i] > 0 else []\n",
        "\n",
        "data_test0 = []\n",
        "data_test  = []\n",
        "for i in range(size_test0):\n",
        "    data_test0 += [round(pd.Series.mean(data_test_csv['GHI'][i*unit:(i+1)*unit])/RE_Capacity3, 3)]\n",
        "    data_test  += [data_test0[i]] if data_test0[i] > 0 else []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jC6yhkysL2Q",
        "outputId": "ad6c1dc5-ebac-4a9e-c5b4-6d8c5f91909c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MAPE_train: 60.46%       MAPE_val: 59.96%         MAPE_test: 72.98%        \n"
          ]
        }
      ],
      "source": [
        "size_train = len(data_train)\n",
        "size_val = len(data_val)\n",
        "size_test = len(data_test)\n",
        "\n",
        "train_input = np.zeros((size_train-1, 1))\n",
        "train_output = np.zeros((size_train-1, 1))\n",
        "for i in range(size_train-1):\n",
        "    train_input[i,:] = data_train[i]\n",
        "    train_output[i,:] = data_train[i+1]\n",
        "\n",
        "val_input = np.zeros((size_val-1, 1))\n",
        "val_output = np.zeros((size_val-1, 1))\n",
        "for i in range(size_val-1):\n",
        "    val_input[i,:] = data_val[i]\n",
        "    val_output[i,:] = data_val[i+1]\n",
        "\n",
        "test_input = np.zeros((size_test-1, 1))\n",
        "test_output = np.zeros((size_test-1, 1))\n",
        "for i in range(size_test-1):\n",
        "    test_input[i,:] = data_test[i]\n",
        "    test_output[i,:] = data_test[i+1]\n",
        "\n",
        "print(\"MAPE_train: {}%\".format(round(100*np.mean(np.abs(train_predict - train_output)/train_output),2)).ljust(25), end=\"\")\n",
        "print(\"MAPE_val: {}%\".format(round(100*np.mean(np.abs(val_predict - val_output)/val_output),2)).ljust(25), end=\"\")\n",
        "print(\"MAPE_test: {}%\".format(round(100*np.mean(np.abs(test_predict - test_output)/test_output),2)).ljust(25))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "VLit2DnnrhlV"
      },
      "outputs": [],
      "source": [
        "# SARSA\n",
        "\n",
        "in_size       = 1\n",
        "out_size      = 5\n",
        "gamma         = 0.99\n",
        "epsilon       = 0.9\n",
        "batch_size    = 128\n",
        "learning_rate = 0.001\n",
        "\n",
        "class SARSA(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SARSA, self).__init__()\n",
        "        self.fc = nn.Linear(in_size, out_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "        \n",
        "def train_net(model, batch, optimizer):\n",
        "    s_lst, a_lst, r_lst, s_prime_lst = [], [], [], []\n",
        "\n",
        "    for transition in batch:\n",
        "        s, a, r, s_prime = transition\n",
        "        s_lst.append(s)\n",
        "        a_lst.append([a])\n",
        "        r_lst.append([r])\n",
        "        s_prime_lst.append(s_prime)\n",
        "\n",
        "    s,a,r,s_prime = torch.tensor(s_lst, dtype=torch.float), torch.tensor(a_lst), \\\n",
        "                    torch.tensor(r_lst, dtype=torch.float), torch.tensor(s_prime_lst, dtype=torch.float)\n",
        "            \n",
        "    for i in range(10):\n",
        "        q_out = model.forward(s).gather(1,a)\n",
        "        target = r + gamma * torch.mean(model.forward(s_prime))\n",
        "        loss = F.mse_loss(q_out, target)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VOEy-4Ortn2",
        "outputId": "3858a4c1-5f71-42f2-aff7-4ba8e56bf9c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "episode: 1\n",
            "MAPE_train: 18.72%       MAPE_val: 21.72%         MAPE_test: 12.65%        \n",
            "CCR_train: 0.591         CCR_val: 0.452           CCR_test: 0.473          \n",
            "------------------------------------------------------------------------------------------\n",
            "episode: 2\n",
            "MAPE_train: 21.83%       MAPE_val: 21.72%         MAPE_test: 12.65%        \n",
            "CCR_train: 0.584         CCR_val: 0.452           CCR_test: 0.473          \n",
            "------------------------------------------------------------------------------------------\n",
            "episode: 3\n",
            "MAPE_train: 21.21%       MAPE_val: 30.66%         MAPE_test: 16.83%        \n",
            "CCR_train: 0.593         CCR_val: 0.611           CCR_test: 0.628          \n",
            "------------------------------------------------------------------------------------------\n",
            "episode: 4\n",
            "MAPE_train: 25.73%       MAPE_val: 29.68%         MAPE_test: 17.01%        \n",
            "CCR_train: 0.599         CCR_val: 0.625           CCR_test: 0.637          \n",
            "------------------------------------------------------------------------------------------\n",
            "episode: 5\n",
            "MAPE_train: 19.32%       MAPE_val: 27.82%         MAPE_test: 16.88%        \n",
            "CCR_train: 0.605         CCR_val: 0.604           CCR_test: 0.619          \n",
            "------------------------------------------------------------------------------------------\n",
            "episode: 6\n",
            "MAPE_train: 26.69%       MAPE_val: 27.81%         MAPE_test: 16.87%        \n",
            "CCR_train: 0.61          CCR_val: 0.604           CCR_test: 0.619          \n",
            "------------------------------------------------------------------------------------------\n",
            "episode: 7\n",
            "MAPE_train: 17.73%       MAPE_val: 16.41%         MAPE_test: 15.69%        \n",
            "CCR_train: 0.597         CCR_val: 0.633           CCR_test: 0.648          \n",
            "------------------------------------------------------------------------------------------\n",
            "episode: 8\n",
            "MAPE_train: 20.29%       MAPE_val: 10.93%         MAPE_test: 10.84%        \n",
            "CCR_train: 0.6           CCR_val: 0.664           CCR_test: 0.692          \n",
            "------------------------------------------------------------------------------------------\n",
            "episode: 9\n",
            "MAPE_train: 19.13%       MAPE_val: 10.97%         MAPE_test: 10.96%        \n",
            "CCR_train: 0.601         CCR_val: 0.662           CCR_test: 0.689          \n",
            "------------------------------------------------------------------------------------------\n",
            "episode: 10\n",
            "MAPE_train: 16.14%       MAPE_val: 11.11%         MAPE_test: 11.75%        \n",
            "CCR_train: 0.593         CCR_val: 0.656           CCR_test: 0.679          \n",
            "------------------------------------------------------------------------------------------\n",
            "episode: 11\n",
            "MAPE_train: 16.43%       MAPE_val: 11.13%         MAPE_test: 12.0%         \n",
            "CCR_train: 0.602         CCR_val: 0.655           CCR_test: 0.678          \n",
            "------------------------------------------------------------------------------------------\n",
            "episode: 12\n",
            "MAPE_train: 18.52%       MAPE_val: 11.13%         MAPE_test: 12.0%         \n",
            "CCR_train: 0.6           CCR_val: 0.655           CCR_test: 0.678          \n",
            "------------------------------------------------------------------------------------------\n",
            "episode: 13\n",
            "MAPE_train: 18.13%       MAPE_val: 11.13%         MAPE_test: 12.0%         \n",
            "CCR_train: 0.594         CCR_val: 0.655           CCR_test: 0.678          \n",
            "------------------------------------------------------------------------------------------\n",
            "episode: 14\n",
            "MAPE_train: 19.53%       MAPE_val: 11.09%         MAPE_test: 10.79%        \n",
            "CCR_train: 0.601         CCR_val: 0.484           CCR_test: 0.495          \n",
            "------------------------------------------------------------------------------------------\n",
            "episode: 15\n",
            "MAPE_train: 19.9%        MAPE_val: 11.13%         MAPE_test: 12.0%         \n",
            "CCR_train: 0.597         CCR_val: 0.655           CCR_test: 0.678          \n",
            "------------------------------------------------------------------------------------------\n",
            "episode: 16\n",
            "MAPE_train: 17.32%       MAPE_val: 11.13%         MAPE_test: 12.0%         \n",
            "CCR_train: 0.589         CCR_val: 0.655           CCR_test: 0.678          \n",
            "------------------------------------------------------------------------------------------\n",
            "episode: 17\n",
            "MAPE_train: 27.71%       MAPE_val: 11.13%         MAPE_test: 12.0%         \n",
            "CCR_train: 0.598         CCR_val: 0.655           CCR_test: 0.678          \n",
            "------------------------------------------------------------------------------------------\n",
            "episode: 18\n",
            "MAPE_train: 18.26%       MAPE_val: 11.13%         MAPE_test: 12.0%         \n",
            "CCR_train: 0.603         CCR_val: 0.655           CCR_test: 0.678          \n",
            "------------------------------------------------------------------------------------------\n",
            "episode: 19\n",
            "MAPE_train: 21.67%       MAPE_val: 11.13%         MAPE_test: 12.0%         \n",
            "CCR_train: 0.597         CCR_val: 0.655           CCR_test: 0.678          \n",
            "------------------------------------------------------------------------------------------\n",
            "episode: 20\n",
            "MAPE_train: 19.97%       MAPE_val: 11.13%         MAPE_test: 12.0%         \n",
            "CCR_train: 0.597         CCR_val: 0.655           CCR_test: 0.678          \n",
            "------------------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Training SARSA\n",
        "\n",
        "E_max   = Battery_Size\n",
        "tdelta  = 1\n",
        "eff_c   = 0.9\n",
        "eff_d   = 0.9\n",
        "soc_min = 0.1\n",
        "soc_max = 0.9\n",
        "P_cmax  = Battery_Size/3\n",
        "P_dmax  = Battery_Size/3\n",
        "beta_c  = 0.01\n",
        "beta_d  = 0.01\n",
        "\n",
        "E_cmax = eff_c*P_cmax*tdelta\n",
        "E_dmax = (1/eff_d)*P_dmax*tdelta\n",
        "C_max  = int(out_size/2)\n",
        "\n",
        "total_episode = 20\n",
        "print_interval = 1\n",
        "\n",
        "model = SARSA()\n",
        "act_train,  act_val,  act_test  = [], [], [] # Controlled Value\n",
        "mape_train, mape_val, mape_test = [], [], [] # Mean Absolute Percentage Error\n",
        "ccr_train,  ccr_val,  ccr_test  = [], [], [] # Complete Compensation Ratio\n",
        "\n",
        "batch = collections.deque(maxlen=batch_size+1)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "for n_epi in range(total_episode):\n",
        "    act_train  += [[]]; act_val  += [[]]; act_test  += [[]]\n",
        "    mape_train += [[]]; mape_val += [[]]; mape_test += [[]]\n",
        "    ccr_train  += [[]]; ccr_val  += [[]]; ccr_test  += [[]]\n",
        "\n",
        "    state = [E_max/2]\n",
        "    i = 0\n",
        "    while i < size_train-1:\n",
        "        for t in range(batch_size):\n",
        "            coin = torch.rand(1).item()\n",
        "            if coin < epsilon:\n",
        "                action = np.random.choice(range(out_size))\n",
        "            else:\n",
        "                Qout = model.forward(torch.tensor(state, dtype=torch.float))\n",
        "                action = np.argmax(Qout.tolist())\n",
        "            E_c = min(max((E_cmax/C_max)*(action-C_max), 0.0), E_max*soc_max - state[0])\n",
        "            E_d = min(max((E_dmax/C_max)*(C_max-action), 0.0), state[0] - E_max*soc_min)\n",
        "\n",
        "            real = train_output[i][0] + eff_d*E_d/tdelta - (1/eff_c)*E_c/tdelta\n",
        "            pred = train_predict[i][0]\n",
        "\n",
        "            E = state[0] + E_c - E_d\n",
        "            P_climit = min(P_cmax, (1/eff_c)*(E_max*soc_max - E)/tdelta)\n",
        "            P_dlimit = min(P_dmax, eff_d*(E - E_max*soc_min)/tdelta)\n",
        "            P_c = min(max(real-pred, 0), P_climit)\n",
        "            P_d = min(max(pred-real, 0), P_dlimit)\n",
        "            E_prime = E + eff_c*P_c*tdelta - (1/eff_d)*P_d*tdelta\n",
        "            disp = 0.0 if np.isclose(real - P_c + P_d, 0) else real - P_c + P_d\n",
        "            error = pred - disp\n",
        "            error_function = abs(error) + beta_c*P_c + beta_d*P_d\n",
        "\n",
        "            next_state = [E_prime]\n",
        "            reward = -error_function\n",
        "            batch.append((state, action, reward, next_state))\n",
        "            state = next_state[:]\n",
        "\n",
        "            act_train[n_epi]  += [E_c - E_d]\n",
        "            mape_train[n_epi]  += [abs((pred-disp)/disp)] if disp != 0 else [0]\n",
        "            ccr_train[n_epi] += [1 if np.isclose(pred-disp,0) else 0]\n",
        "            i += 1\n",
        "            if i == size_train-1:\n",
        "                break\n",
        "\n",
        "        if n_epi != 0:\n",
        "            train_net(model, batch, optimizer)\n",
        "    \n",
        "    state = [E_max/2]\n",
        "    for k in range(size_val-1):\n",
        "        Qout = model.forward(torch.tensor(state, dtype=torch.float))\n",
        "        action = np.argmax(Qout.tolist())\n",
        "        E_c = min(max((E_cmax/C_max)*(action-C_max), 0.0), E_max*soc_max - state[0])\n",
        "        E_d = min(max((E_dmax/C_max)*(C_max-action), 0.0), state[0] - E_max*soc_min)\n",
        "\n",
        "        real = val_output[k][0] + eff_d*E_d/tdelta - (1/eff_c)*E_c/tdelta\n",
        "        pred = val_predict[k][0]\n",
        "\n",
        "        E = state[0] + E_c - E_d\n",
        "        P_climit = min(P_cmax, (1/eff_c)*(E_max*soc_max - E)/tdelta)\n",
        "        P_dlimit = min(P_dmax, eff_d*(E - E_max*soc_min)/tdelta)\n",
        "        P_c = min(max(real-pred, 0), P_climit)\n",
        "        P_d = min(max(pred-real, 0), P_dlimit)\n",
        "        E_prime = E + eff_c*P_c*tdelta - (1/eff_d)*P_d*tdelta\n",
        "        disp = 0.0 if np.isclose(real - P_c + P_d, 0) else real - P_c + P_d\n",
        "        error = pred - disp\n",
        "        error_function = abs(error) + beta_c*P_c + beta_d*P_d\n",
        "\n",
        "        next_state = [E_prime]\n",
        "        state = next_state[:]\n",
        "\n",
        "        act_val[n_epi]  += [E_c - E_d]\n",
        "        mape_val[n_epi]  += [abs((pred-disp)/disp)] if disp != 0 else [0]\n",
        "        ccr_val[n_epi] += [1 if np.isclose(pred-disp,0) else 0]\n",
        "    \n",
        "    state = [E_max/2]\n",
        "    for l in range(size_test-1):\n",
        "        Qout = model.forward(torch.tensor(state, dtype=torch.float))\n",
        "        action = np.argmax(Qout.tolist())\n",
        "        E_c = min(max((E_cmax/C_max)*(action-C_max), 0.0), E_max*soc_max - state[0])\n",
        "        E_d = min(max((E_dmax/C_max)*(C_max-action), 0.0), state[0] - E_max*soc_min)\n",
        "\n",
        "        real = test_output[l][0] + eff_d*E_d/tdelta - (1/eff_c)*E_c/tdelta\n",
        "        pred = test_predict[l][0]\n",
        "\n",
        "        E = state[0] + E_c - E_d\n",
        "        P_climit = min(P_cmax, (1/eff_c)*(E_max*soc_max - E)/tdelta)\n",
        "        P_dlimit = min(P_dmax, eff_d*(E - E_max*soc_min)/tdelta)\n",
        "        P_c = min(max(real-pred, 0), P_climit)\n",
        "        P_d = min(max(pred-real, 0), P_dlimit)\n",
        "        E_prime = E + eff_c*P_c*tdelta - (1/eff_d)*P_d*tdelta\n",
        "        disp = 0.0 if np.isclose(real - P_c + P_d, 0) else real - P_c + P_d\n",
        "        error = pred - disp\n",
        "        error_function = abs(error) + beta_c*P_c + beta_d*P_d\n",
        "\n",
        "        next_state = [E_prime]\n",
        "        state = next_state[:]\n",
        "\n",
        "        act_test[n_epi]  += [E_c - E_d]\n",
        "        mape_test[n_epi]  += [abs((pred-disp)/disp)] if disp != 0 else [0]\n",
        "        ccr_test[n_epi] += [1 if np.isclose(pred-disp,0) else 0]\n",
        "    \n",
        "    if (n_epi+1)%print_interval == 0:\n",
        "        MAPE_train  = round(100*np.mean(mape_train[n_epi]),2)\n",
        "        MAPE_val    = round(100*np.mean(mape_val[n_epi]),2)\n",
        "        MAPE_test   = round(100*np.mean(mape_test[n_epi]),2)\n",
        "        CCR_train = round(np.mean(ccr_train[n_epi]),3)\n",
        "        CCR_val   = round(np.mean(ccr_val[n_epi]),3)\n",
        "        CCR_test  = round(np.mean(ccr_test[n_epi]),3)\n",
        "\n",
        "        print(\"episode: {}\".format(n_epi+1))\n",
        "        print(\"MAPE_train: {}%\".format(MAPE_train).ljust(25), end=\"\")\n",
        "        print(\"MAPE_val: {}%\".format(MAPE_val).ljust(25), end=\"\")\n",
        "        print(\"MAPE_test: {}%\".format(MAPE_test).ljust(25))\n",
        "        print(\"CCR_train: {}\".format(CCR_train).ljust(25), end=\"\")\n",
        "        print(\"CCR_val: {}\".format(CCR_val).ljust(25), end=\"\")\n",
        "        print(\"CCR_test: {}\".format(CCR_test).ljust(25))\n",
        "        print(\"------------------------------------------------------------------------------------------\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "B0o8d2xWyrzv"
      },
      "outputs": [],
      "source": [
        "# Produce results\n",
        "\n",
        "select_num = np.argmin(np.mean(mape_val,axis=1))\n",
        "select = pd.DataFrame(np.array(act_test[select_num][:]))\n",
        "select.to_csv(\"result/Solar_Model2_ECC+_\"+str(int(100*E_max))+\".csv\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyN1B80qncnXalRhvRxR+3mQ",
      "collapsed_sections": [],
      "mount_file_id": "1MNeyVXVucm8Rke-hDQ1tSP_8wOfyU8_7",
      "name": "DeepComp_Comparison_SARSA_Solar.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
